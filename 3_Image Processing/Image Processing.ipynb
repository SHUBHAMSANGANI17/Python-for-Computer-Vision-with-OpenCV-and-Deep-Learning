{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Goals\n",
    " - Learn various image processing operations\n",
    " - Perform image operations such as Smoothing, Blurring, Morphological Operations\n",
    " - Grab properties such as color spaces and histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 1 - Color Mappngs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far we worked with RGB color spaces\n",
    "- There are some other models like HSL (Hue, Saturation, Lightness) and\n",
    "HSV(Hue, Saturation and Value)\n",
    "- HSL and HSV are more aligned with human vision actually perceives\n",
    "- While in this course we deal with RGB images, its a good idea to understand about HSV and HSL colorspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../Data/00-puppy.jpg')\n",
    "plt.imshow(img) # BGR cahannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to RGB\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to HSV\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2HSV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 2 - Blending and Pasting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blend images   \n",
    "Formula:  \n",
    "new_pixel = alpha x pixel_1(1st image) + beta x pixel_2(2nd image) + gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.cvtColor(cv2.imread('../Data/dog_backpack.png'),\n",
    "                    cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(cv2.imread('../Data/watermark_no_copy.png'),\n",
    "                    cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('img1 shape: ',img1.shape)\n",
    "print('img2 shape: ',img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending images of same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize to equal sizes\n",
    "img1 = cv2.resize(img1,(1200,1200))\n",
    "img2 = cv2.resize(img2,(1200,1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('img1 shape: ',img1.shape)\n",
    "print('img2 shape: ',img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(src1 = img1,alpha = 0.5,\n",
    "                         src2 = img2,beta = 0.5,gamma = 0)\n",
    "plt.imshow(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(src1 = img1,alpha = 0.8,\n",
    "                         src2 = img2,beta = 0.2,gamma = 0)\n",
    "plt.imshow(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay small image on top of larger image\n",
    "#numpy reassignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.cvtColor(cv2.imread('../Data/dog_backpack.png'),\n",
    "                    cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(cv2.imread('../Data/watermark_no_copy.png'),\n",
    "                    cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.resize(img2,(600,600)) #img2 is smaller than img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img = img1\n",
    "small_img = img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = 0\n",
    "y_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in numpy x axis is vertical and y axis is horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_end = x_offset + small_img.shape[1]\n",
    "y_end = y_offset + small_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img[y_offset:y_end,x_offset:x_end] = small_img\n",
    "plt.imshow(large_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend images of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.cvtColor(cv2.imread('../Data/dog_backpack.png'),\n",
    "                    cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(cv2.imread('../Data/watermark_no_copy.png'),\n",
    "                    cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.resize(img2,(600,600)) #img2 is smaller than img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = 934 - 600\n",
    "y_offset = 1401 - 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols,channels = img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region of interest\n",
    "roi = img1[y_offset:1401,x_offset:934]\n",
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img2gray,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv = cv2.bitwise_not(img2gray)\n",
    "plt.imshow(mask_inv,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can see the image is 2D now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_bgd = np.full(img2.shape,255,dtype=np.uint8)\n",
    "white_bgd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(white_bgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk = cv2.bitwise_or(white_bgd,white_bgd,mask=mask_inv)\n",
    "plt.imshow(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = cv2.bitwise_or(img2,img2,mask = mask_inv)\n",
    "plt.imshow(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_roi = cv2.bitwise_or(roi,fg)\n",
    "plt.imshow(final_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img = img1\n",
    "small_img = final_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img[y_offset:y_offset+small_img.shape[0],\n",
    "         x_offset:x_offset+small_img.shape[1]] = small_img\n",
    "plt.imshow(large_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 3 Image Threshodling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thresholding is fundamentally a very simple method of segmenting an image into different parts\n",
    "- Threshodling will convert an image to white or black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../Data/rainbow.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read as grayscale\n",
    "img_gray = cv2.imread('../Data/rainbow.jpg',0)\n",
    "plt.imshow(img_gray,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Threshold types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh1 = cv2.threshold(img_gray,thresh=img.max()/2,maxval = 255,\n",
    "             type = cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresh1,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh1 = cv2.threshold(img_gray,thresh=img.max()/2,maxval = 255,\n",
    "             type = cv2.THRESH_BINARY_INV)\n",
    "print(ret)\n",
    "plt.imshow(thresh1,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh1 = cv2.threshold(img_gray,thresh=img.max()/2,maxval = 255,\n",
    "             type = cv2.THRESH_TRUNC)\n",
    "print(ret)\n",
    "plt.imshow(thresh1,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../Data/crossword.jpg',0)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thr1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "show_img(thr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                            cv2.THRESH_BINARY,11,9)\n",
    "show_img(thr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(thr1,0.7,thr2,0.4,0)\n",
    "show_img(blended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 4 Blurring and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blurring/Smoothing is combined with edge detection\n",
    "- Edge detection algorithms detect too many edges when shown a high resolution image without any blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Methods\n",
    " - Gamma Correction:\n",
    "   - can be applied to an image to make it appear brighter or darker depending on the Gamma value chosen\n",
    " - Kernel Based Filters\n",
    "   - can be applied over an image to produce a variet of effects\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    img = cv2.imread('../Data/bricks.jpg').astype(np.float32) / 255\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = load_img()\n",
    "show_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.power(i,gamma)\n",
    "show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "show_img(cv2.putText(img,text = 'bricks', org = (10,600),fontFace = font,\n",
    "            fontScale=10,color = (255,0,0),thickness = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),dtype=np.float32) / 25\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "show_img(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "show_img(cv2.putText(img,text = 'bricks', org = (10,600),fontFace = font,\n",
    "            fontScale=10,color = (255,0,0),thickness = 5))\n",
    "print('reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.blur(img,ksize = (10,10))\n",
    "show_img(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "show_img(cv2.putText(img,text = 'bricks', org = (10,600),fontFace = font,\n",
    "            fontScale=10,color = (255,0,0),thickness = 5))\n",
    "print('reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_blur = cv2.GaussianBlur(img,(5,5),10)\n",
    "show_img(gaussian_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "show_img(cv2.putText(img,text = 'bricks', org = (10,600),fontFace = font,\n",
    "            fontScale=10,color = (255,0,0),thickness = 5))\n",
    "print('reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_blur = cv2.medianBlur(img,5)\n",
    "show_img(median_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread('../Data/sammy.jpg'),cv2.COLOR_BGR2RGB)\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_img = cv2.imread('../Data/sammy_noise.jpg')\n",
    "show_img(noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv2.medianBlur(noisy_img,5)\n",
    "show_img(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "show_img(cv2.putText(img,text = 'bricks', org = (10,600),fontFace = font,\n",
    "            fontScale=10,color = (255,0,0),thickness = 5))\n",
    "print('reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.bilateralFilter(img,9,75,75)\n",
    "show_img(blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 5 Morphological Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MO are sets of kernels that can achienve a variety of effects such as reducing noise\n",
    "- Certain operators are very good at reducing black points on a white background\n",
    "- Certain operators can also achieve an erosion and dilation effect that can add or erode from an existing image\n",
    "- This effect is mostly seen on text data, so we will practisce various morphological operators on some simple white text on a  balck background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    blank_img = np.zeros((600,600))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(blank_img,text='ABCDE',org=(20,400),fontFace = font,\n",
    "               fontScale = 5,color= (255,255,255),thickness = 30)\n",
    "    return blank_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv2.erode(img,kernel,iterations = 1)\n",
    "show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv2.erode(img,kernel,iterations = 4)\n",
    "show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "#creating white noise\n",
    "white_noise = np.random.randint(0,2,size=(600,600))\n",
    "show_img(white_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = white_noise * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_img = white_noise + img\n",
    "show_img(noise_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening is used to clean up the noise\n",
    "opening = cv2.morphologyEx(noise_img,cv2.MORPH_OPEN,kernel)\n",
    "show_img(opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "black_noise = np.random.randint(0,2,(600,600))\n",
    "black_noise = black_noise * -255\n",
    "black_noise = black_noise + img\n",
    "black_noise[black_noise==-255] =0\n",
    "show_img(black_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(black_noise,cv2.MORPH_CLOSE,kernel)\n",
    "show_img(closing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img()\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)\n",
    "show_img(gradient)\n",
    "#thisis the difference between erosion and dialation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 6 - Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An image gradient is a directional change in the intensity or color in an image\n",
    "- Gradients can be calculated in a specific direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread('../Data/sudoku.jpg',0)\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "show_img(sobelx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "show_img(sobely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "show_img(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(sobelx,0.6,sobely,0.3,0)\n",
    "show_img(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thr = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "show_img(thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 7 - Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Histogram is the visual representation of the distribution of a continous feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_horse = cv2.imread('../Data/horse.jpg') #for opencv\n",
    "show_horse = cv2.cvtColor(dark_horse,cv2.COLOR_BGR2RGB) # for matplotlib\n",
    "\n",
    "rainbow = cv2.imread('../Data/rainbow.jpg')\n",
    "show_rainbow = cv2.cvtColor(rainbow,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "bricks = cv2.imread('../Data/bricks.jpg')\n",
    "show_bricks = cv2.cvtColor(bricks,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_bricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([bricks],channels=[0],mask=None,\n",
    "             histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([dark_horse],channels=[0],mask=None,\n",
    "             histSize=[256],ranges=[0,256])\n",
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ('b','g','r')\n",
    "\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.title('Histogram of Blue bricks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is a method of contrast adjustment based on the image's histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making the cumulative histogram much more linear... means you are increasing the contrast of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rainbow\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating mask\n",
    "mask = np.zeros(img.shape[:2],np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[300:400,100:400] = 255\n",
    "plt.imshow(mask,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img = cv2.bitwise_and(img,img,mask=mask)\n",
    "show_masked_img = cv2.bitwise_and(show_rainbow,show_rainbow,mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mask_values_red = cv2.calcHist([rainbow],[2],mask,[256],[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_mask_values_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gorilla = cv2.imread('../Data/gorilla.jpg',0)\n",
    "show_img(gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([gorilla],[0],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_gorilla = cv2.equalizeHist(gorilla)\n",
    "show_img(eq_gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_values = cv2.calcHist([eq_gorilla],[0],mask=None,histSize=[256],ranges=[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_gorilla = cv2.imread('../Data/gorilla.jpg')\n",
    "show_gorilla = cv2.cvtColor(color_gorilla,cv2.COLOR_BGR2RGB)\n",
    "show_img(show_gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(color_gorilla,cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv[:,:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_color_gorilla = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(eq_color_gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
